ğŸ“š Knowledge Grounding App
Ground answers from your own knowledge base â€” extracted from PDFs, MP4s, or YouTube videos â€” and query them using a conversational AI (Gemini + Semantic Search).
Supports login/signup with per-user isolated vector stores and scoring system.

ğŸ“ Folder Structure
bash
Copy
Edit
knowledge_grounding/
â”œâ”€â”€ app.py                      # Streamlit UI app with login, upload, QA
â”œâ”€â”€ core.py                     # Core processing logic: embeddings, vector search, LLM
â”œâ”€â”€ users.json                  # Registered users with hashed passwords
â”œâ”€â”€ .env                        # Environment file with GEMINI_API_KEY
â”œâ”€â”€ data/
â”‚   â””â”€â”€ users/
â”‚       â””â”€â”€ <username>/
â”‚           â”œâ”€â”€ raw_text/       # Original uploaded files
â”‚           â””â”€â”€ faiss_index/    # Vector index & context chunks
â”‚               â”œâ”€â”€ index.faiss
â”‚               â””â”€â”€ docs.txt
â”œâ”€â”€ requirements.txt            # Python package dependencies
ğŸ”§ Setup Instructions
Clone the repo

bash
Copy
Edit
git clone https://github.com/your-username/knowledge-grounding-app.git
cd knowledge_grounding-app
Install dependencies

bash
Copy
Edit
pip install -r requirements.txt
Install FFmpeg

Download from https://ffmpeg.org/download.html

Add to core.py: update FFMPEG_PATH = r"C:\path\to\ffmpeg\bin"

Add .env file with your Gemini API key

ini
Copy
Edit
GEMINI_API_KEY=your_google_gemini_api_key
Run the app

bash
Copy
Edit
streamlit run app.py
ğŸ” Login & Signup
Each user registers with:

Full name

Unique User ID

Password + confirmation

Passwords are hashed securely using bcrypt.

After login:

Data is saved in a private folder: data/users/<user_id>/

Vector index and uploaded documents are not shared across users.

ğŸ“‚ Upload & Process
You can upload:

ğŸ“„ PDF files â†’ Extracted using PyMuPDF

ğŸ¥ MP4 video files â†’ Transcribed using OpenAI Whisper

ğŸ”— YouTube links â†’ Downloaded with yt_dlp, audio extracted and transcribed

All content is:

ğŸ” Chunked

ğŸ”¡ Embedded using sentence-transformers

ğŸ’¾ Stored in FAISS index per user

ğŸ’¬ Ask Questions
Ask anything grounded on your uploaded data.
The app:

Retrieves top-3 relevant chunks via FAISS

Sends context + query to Gemini 1.5 Flash

Gets:

âœï¸ Final answer

ğŸ¤– Self-reported Gemini confidence score (0â€“100)

Computes:

ğŸ“Š Cosine similarity between question and top chunk

ğŸ§  Accuracy Scores
Score	Meaning
ğŸ“Š Similarity Score	Measures how semantically close your question is to the best matching document chunk (via cosine similarity)
ğŸ¤– Gemini Confidence	Gemini's own confidence in the answer it generated using the given context (0â€“100)

â„¹ï¸ Click the "How it's calculated" dropdown under each metric for explanation.

ğŸ§ª Example Usage
Upload SampleVideo.mp4
Ask: "Who won the match?"

âœ… App transcribes video, chunks and indexes it

ğŸ¤– Gemini returns: "England won the 3rd Test match against India by 22 runs."

ğŸ“Š Similarity: 84.32%

ğŸ¤– Gemini Confidence: 95%

ğŸ§° Tech Stack
Component	Tech Used
ğŸ§  LLM	Google Gemini 1.5 Flash (via API)
ğŸ“‰ Embeddings	sentence-transformers
ğŸ” Vector search	FAISS
ğŸ§¾ PDF extraction	PyMuPDF (fitz)
ğŸ—£ï¸ Transcription	OpenAI Whisper
ğŸ“º YouTube download	yt_dlp
ğŸ§ª UI Framework	Streamlit
ğŸ” Auth	Manual with bcrypt + JSON

ğŸ“¦ Requirements
requirements.txt

txt
Copy
Edit
streamlit
bcrypt
whisper
PyMuPDF
faiss-cpu
sentence-transformers
scikit-learn
yt_dlp
python-dotenv
google-generativeai